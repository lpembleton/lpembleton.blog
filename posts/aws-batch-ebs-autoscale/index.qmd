---
title: "EBS Auto-scaling on AWS Batch"
description: "An introductory guide to setting up EBS auto-scaling on AWS Batch for use in Nextflow"
author: "LW Pembleton"
date: "29/11/2022"
---

\# EBS Auto-scaling on AWS Batch

!\[Photo by \[Simon Goetz\](https://unsplash.com/\@slgoetz) on Unsplash\](images/simon-goetz-feeredToXK4-unsplash.jpg)

Anyone who has tried running bioinformatic pipelines on AWS batch with a workflow manager such as Nextflow will be well aware of the common error

`error: No space left on device`

that can plague a pipeline. Yes you can adjust your EBS allocation with specific AMI images or launch configurations and tailor them to specific tasks, but the dynamic nature of bio~~informatics~~logy means this will likely be ongoing cat ðŸˆ and mouse ðŸ game.

Yes Nextflow has the fantastic resume feature if your pipeline has already completed a large proportion of tasks, unfortunately though the config file is not reanalysed upon resume, so you cannot point to a new AMI with an increased EBS volume.

The solution? automatic scaling of your EBS volumes in real time. Essentially there is a script that resides within your AMI that contentiously monitors disk usage and just before you reach 100% it provisions a new EBS volumes mounting it directly to your running EC2 instance. You also get the added benefit of better EBS cost optimisation ðŸ’° as you no longer need to 'over provision' your batch EC2 instances.

The setup can be split into two components, installing the auto-scaling scripts in your AMI and updating your Batch compute environments with appropriate permissions.

### Setup an appropriate IAM Role

1.  Click **Create role** under the IAM AWS console and select **AWS service** as the trusted entity type and **EC2** as the use case, then click **Next**.

2.  Ciick **Create policy** and select the **JSON** tab.

3.  Paste the following JSON code and click **Next**.

``` json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ec2:AttachVolume",
                "ec2:DescribeVolumeStatus",
                "ec2:DescribeVolumes",
                "ec2:DescribeTags",
                "ec2:ModifyInstanceAttribute",
                "ec2:DescribeVolumeAttribute",
                "ec2:CreateVolume",
                "ec2:DeleteVolume",
                "ec2:CreateTags"
            ],
            "Resource": "*"
        }
    ]
}
```

4.  Add any tags if applicable and click **Next**

5.  Give your policy a name e.g. *amazon-ebs-autoscale-policy* and click **Create policy**

6.  Now under the Add permission menu of your new IAM Role select your newly created policy, i.e. *amazon-ebs-autoscale-policy* and click **Next**

7.  Give your Role and name, e.g. *amazon-ebs-autoscale-role* and click **Create role**

    You also need to add the *amazon-ebs-autoscale-policy policy* role to the *ecsInstanceRole*role you use in your AWS Batch compute environments.

8.  Under **Roles** in the AWS IAM console find and click the *ecsInstanceRole role.*

9.  Click **Add permission** and select **Attach policies**. Find/search for your new *amazon-ebs-autoscale-policy*, select it and click **Attach policies.**

### Install the auto-scale scripts

1.  Fetch or clone the amazon-ebs-autoscale repository to your local computer.

2.  Edit the EBS mount location to the volume that docker utilises by added the `-m /var/lib/docker` parameter to the `install.sh` command in the `amazon-ebs-autoscale/templates/cloud-init-userdata.yaml`file

3.  Specify the initial drive to use for the mountpoint to be `/dev/xvdba` with the `-d` parameter

4.  By default the 100GiB volume will be initially provision at startup to change this add the -s parameter again to the the `install.sh` command in the `amazon-ebs-autoscale/templates/cloud-init-userdata.yaml`file. For example to reduce it to the 30GB use `-s 30`

5.  the `runcmd:` section should now look something like:

``` bash
runcmd:
  - curl -s "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "/tmp/awscliv2.zip"
  - unzip -q /tmp/awscliv2.zip -d /tmp && /tmp/aws/install
  - EBS_AUTOSCALE_VERSION=$(curl --silent "https://api.github.com/repos/awslabs/amazon-ebs-autoscale/releases/latest" | jq -r .tag_name)
  - cd /opt && git clone https://github.com/awslabs/amazon-ebs-autoscale.git
  - cd /opt/amazon-ebs-autoscale && git checkout $EBS_AUTOSCALE_VERSION
  - sh /opt/amazon-ebs-autoscale/install.sh -m /var/lib/docker -d /dev/xvdba -s 30 2>&1 > /var/log/ebs-autoscale-install.log
```

5.  Install the amazon-ebs-autoscale scripts with your defined paramaters into your chosen AMI you can use the `aws ec2 run-instance` command from the aws-cli. An example of launching your chosen AMI and installing the amazon-ebs-autoscale scripts is

``` bash
aws ec2 run-instances --image-id YOUR-AMI-ID \
  --key-name YOUR-KEY-PAIR-NAME \
  --subnet-id YOUR-SUBNET-ID \
  --user-data file://./templates/cloud-init-userdata.yaml \
  --count 1 \
  --security-group-ids YOUR-SECURITY-GROUP-ID \
  --instance-type t2.micro \
  --iam-instance-profile Name=amazon-ebs-autoscale-role
```

6.  Running this from your command line will launch a EC2 instance which you can then save as a new AMI with an appropriate name. (see my Nextflow on AWS Batch blog post for details on how to save AMIs)

7.  
