[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Dr Luke Pembleton",
    "section": "",
    "text": "ðŸŽ“ Doctor of Philosophy, Molecular Genetics from La Trobe University, 2014\nðŸŽ“ Bachelor of Agricultural Science, Rural Technology from the University of Queensland, 2010\n\n\nDr Luke Pembleton is a Genomic Breeding Scientist and Strategic Science Manager at Barenbrug. He leads the development and implementation of commercial genomic breeding and associated â€˜omicâ€™ technologies.\n\n\n\nMost of my technical work is focused on the fields of ðŸ§¬ Genomics, Genomic Selection and Genomic Breeding in plants, primarily forages ðŸŒ±. Skilled in bioinformatics ðŸ‘¨â€ðŸ’» and passionate about the R programing language. Enjoy developing cloud computing â˜ï¸ environments for research and production pipelines, often orchestrated with the workflow manager Nextflow ðŸ”‚.\n\n\n\n Genomic Breeding Scientist | Strategic Science Manager\nBarenbrug | August 2021 - Current\n~\n Senior Research Scientist\nAgriculture Victoria Research | April 2017 - August 2021\n~\n Research Scientist\nAgriculture Victoria Research | October 2014 - March 2017\n~\n Research Assistant\nVictorian Department of Primary Industries | June 2009 - December 2009"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesnâ€™t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "lpembleton.site",
    "section": "",
    "text": "An introductory guide to setting up EBS auto-scaling on AWS Batch for use in Nextflow\n\n\n\n\n\n\nMay 11, 2024\n\n\nLW Pembleton\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nAn introductory guide to setting up Nextflow with AWS Batch\n\n\n\n\n\n\nJan 11, 2024\n\n\nLW Pembleton\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/publications.html",
    "href": "publications/publications.html",
    "title": "Publications",
    "section": "",
    "text": "See also:"
  },
  {
    "objectID": "publications/publications.html#publications-by-date",
    "href": "publications/publications.html#publications-by-date",
    "title": "Publications",
    "section": "Publications by date",
    "text": "Publications by date\nðŸ“„ Yongjun Li, Sukhjiwan Kaur, Luke W. Pembleton, Hossein Valipour-Kahrood, Garry M. Rosewarne, Hans D. Daetwyler (2022). Strategies of preserving genetic diversity while maximizing genetic response from implementing genomic selection in pulse breeding programs. Theoretical and Applied Genetics, 1-16.\nErez Naim-Feil, Luke W. Pembleton, Laura E. Spooner, Alix L. Malthouse, Amy Miner, Melinda Quinn, Renata M. Polotnianka, Rebecca C. Baillie, German C. Spangenberg, Noel O. I. Cogan (2021). The characterization of key physiological traits of medicinal cannabis (Cannabis sativa L.) as a tool for precision breeding. BMC Plant Biology, 21(1).\nLydia M. Cranston, Keith G. Pembleton, Lucy L. Burkitt, Andrew Curtis, Daniel J. Donaghy, Cameron J. P. Gourley, Kerry C. Harrington, James L. Hills, Luke W. Pembleton, Richard P. Rawnsley (2020). The role of forage management in addressing challenges facing Australasian dairy farming. Anim. Prod. Sci., 60(1).\nAbdulqader Jighly, Zibei Lin, Luke W. Pembleton, Noel O. I. Cogan, German C. Spangenberg, Ben J. Hayes, Hans D. Daetwyler (2019). Boosting Genetic Gain in Allogamous Crops via Speed Breeding and Genomic Selection. Frontiers in Plant Science, 10.\nJunping Wang, Pieter Badenhorst, Andrew Phelan, Luke Pembleton, Fan Shi, Noel Cogan, German Spangenberg, Kevin Smith (2019). Using Sensors and Unmanned Aircraft Systems for High-Throughput Phenotyping of Biomass in Perennial Ryegrass Breeding Trials. Frontiers in Plant Science, 10.\nB. M. Caruana, L. W. Pembleton, F. Constable, B. Rodoni, A. T. Slater, N. O. I. Cogan (2019). Validation of Genotyping by Sequencing Using Transcriptomics for Diversity and Application of Genomic Selection in Tetraploid Potato. Frontiers in Plant Science, 10.\nLuke W. Pembleton, Courtney Inch, Rebecca C. Baillie, Michelle C. Drayton, Preeti Thakur, Yvonne O. Ogaji, German C. Spangenberg, John W. Forster, Hans D. Daetwyler, Noel O. I. Cogan (2018). Exploitation of data from breeding programs supports rapid implementation of genomic selection for key agronomic traits in perennial ryegrass. Theoretical and Applied Genetics, 131(9).\nM. Michelle Malmberg, Luke W. Pembleton, Rebecca C. Baillie, Michelle C. Drayton, Shimna Sudheesh, Sukhjiwan Kaur, Hiroshi Shinozuka, Preeti Verma, German C. Spangenberg, Hans D. Daetwyler, John W. Forster, Noel O.I. Cogan (2018). Genotyping-by-sequencing through transcriptomics: implementation in a range of crop species with varying reproductive habits and ploidy levels. Plant Biotechnology Journal, 16(4).\nRebecca C. Baillie, Michelle C. Drayton, Luke W. Pembleton, Sukhjiwan Kaur, Richard A. Culvenor, Kevin F. Smith, German C. Spangenberg, John W. Forster, Noel O. I. Cogan (2017). Generation and Characterisation of a Reference Transcriptome for Phalaris (Phalaris aquatica L.). Agronomy, 7(1).\nZibei Lin, Junping Wang, Noel O.I. Cogan, Luke W. Pembleton, Pieter Badenhorst, John W. Forster, German C. Spangenberg, Ben J. Hayes, Hans D. Daetwyler (2017). Optimizing Resource Allocation in a Genomic Breeding Program for Perennial Ryegrass to Balance Genetic Gain, Cost, and Inbreeding. Crop Science, 57(1).\nLuke W. Pembleton, Michelle C. Drayton, Melissa Bain, Rebecca C. Baillie, Courtney Inch, German C. Spangenberg, Junping Wang, John W. Forster, Noel O. I. Cogan (2016). Targeted genotyping-by-sequencing permits cost-effective identification and discrimination of pasture grass species and cultivars. Theoretical and Applied Genetics, 129(5).\nJunping Wang, Luke W. Pembleton, Noel O. I. Cogan, John W. Forster (2016). Evidence for Heterosis in Italian Ryegrass (Lolium multiflorum Lam.) Based on Inbreeding Depression in F2 Generation Offspring from Biparental Crosses. Agronomy, 6(4).\nL. W. Pembleton, J. Wang, G. C. Spangenberg, J. W. Forster, N. O. I. Cogan (2016). Low-cost automated biochemical phenotyping for optimised nutrient quality components in ryegrass breeding. Crop Pasture Sci., 67(8).\nZibei Lin, Noel O. I. Cogan, Luke W. Pembleton, German C. Spangenberg, John W. Forster, Ben J. Hayes, Hans D. Daetwyler (2016). Genetic Gain and Inbreeding from Genomic Selection in a Simulated Commercial Breeding Program for Perennial Ryegrass. The Plant Genome, 9(1).\nLuke Pembleton, Hiroshi Shinozuka, Junping Wang, German Spangenberg, John Forster, Noel Cogan (2015). Design of an F1 hybrid breeding strategy for ryegrasses based on selection of self-incompatibility locus-specific alleles. Frontiers in Plant Science, 6.\nJ. Wang, N. O. I. Cogan, L. W. Pembleton, J. W. Forster (2015). Variance, inter-trait correlation, heritability and trait-marker association of herbage yield, nutritive values, and morphological characteristics in Italian ryegrass (Lolium multiflorum Lam.). Crop Pasture Sci., 66(9).\nJunping Wang, Luke W. Pembleton, Rebecca C. Baillie, Michelle C. Drayton, Melanie L. Hand, Melissa Bain, Timothy I. Sawbridge, German C. Spangenberg, John W. Forster, Noel O. I. Cogan (2014). Development and implementation of a multiplexed single nucleotide polymorphism genotyping tool for differentiation of ryegrass species and cultivars. Molecular Breeding, 33(2).\nL. W. Pembleton, J. Wang, N. O. I. Cogan, J. E. Pryce, G. Ye, C. K. Bandaranayake, M. L. Hand, R. C. Baillie, M. C. Drayton, K. Lawless, S. Erb, M. P. Dobrowolski, T. I. Sawbridge, G. C. Spangenberg, K. F. Smith, J. W. Forster (2013). Candidate gene-based association genetics analysis of herbage quality traits in perennial ryegrass (Lolium perenne L.). Crop Pasture Sci., 64(3).\nBenjamin J. Hayes, Noel O. I. Cogan, Luke W. Pembleton, Michael E. Goddard, Junping Wang, German C. Spangenberg, John W. Forster (2013). Prospects for genomic selection in forage plant species. Plant Breeding, 132(2).\nLuke W. Pembleton, Noel O. I. Cogan, John W. Forster (2013). StAMPP: an R package for calculation of genetic differentiation and structure of mixed-ploidy level populations. Molecular Ecology Resources, 13(5).\nSukhjiwan Kaur, Luke W. Pembleton, Noel O. I. Cogan, Keith W. Savin, Tony Leonforte, Jeffrey Paull, Michael Materne, John W. Forster (2012). Transcriptome sequencing of field pea and faba bean for discovery and validation of SSR genetic markers. BMC Genomics, 13(1).\nSukhjiwan Kaur, Noel O. I. Cogan, Luke W. Pembleton, Maiko Shinozuka, Keith W. Savin, Michael Materne, John W. Forster (2011). Transcriptome sequencing of lentil based on second-generation technology permits large-scale unigene assembly and SSR marker discovery. BMC Genomics, 12(1)."
  },
  {
    "objectID": "posts/nextflow-on-aws-batch/index.html",
    "href": "posts/nextflow-on-aws-batch/index.html",
    "title": "Nextflow on AWS Batch",
    "section": "",
    "text": "Photo by Jenessaa Lu on Unsplash\n\n\nThe following is a general guide on how to set up Nextflow with AWS batch as the compute environment. I would highly recommended that you use your local environment or at least a smaller test dataset for pipeline development, transferring to AWS batch when in a working production state.\nAlthough it seems like Gandalf trims his beard more often than Amazon updates their AWS user interface, I cannot guarantee the included menu screenshots will look the same on your system. However, hopefully they will still provide sufficient information to determine the appropriate settings and options. Reach out if you feel I need to update this guide.\nFirstly you need to create a new IAM with more appropriate permissions tailored to the requirements listed in Nextflow documentation. It is strongly recommended that do not use your root account to run Nextflow pipelines.\n\nOpen the IAM management console on AWS and add a new user\nEnter an appropriate user name for example â€˜Nextflow-accessâ€™. Under access type, select programmatic access\n\nNext you need to create a user group for the new user to sit within. Generally on AWS you will apply permissions to a user group rather than a specific user. Additionally, this allows you to set up multiple separate people within the â€˜Nextflow groupâ€™. Again enter an appropriate name and click Create group\nAdd any metadata tags if appropriate\nClick Create user. You should be greeted with a new page that includes a Access Key ID and SCA (ðŸ“ take note of these keys as you will need them towards the end of this guide)\n\nNow that you have your new user and Nextflow group you will need to apply the required permissions.\n\nFrom the IAM user panel click User groups select your recently creates â€˜nextflowâ€™ group, and under the permissions menu click on the Attach policy button\n\nClick Create policy\n\nUse the visual editor to add all the required permissions\n\nMinimal permissions policies to be attached to the AWS account used by Nextflow are:\n\nTo interface AWS Batch:\n\"batch:DescribeJobQueues\"\n\"batch:CancelJob\"\n\"batch:SubmitJob\"\n\"batch:ListJobs\"\n\"batch:DescribeComputeEnvironments\"\n\"batch:TerminateJob\"\n\"batch:DescribeJobs\"\n\"batch:RegisterJobDefinition\"\n\"batch:DescribeJobDefinitions\"\nTo be able to see the EC2 instances:\n\"ecs:DescribeTasks\"\n\"ec2:DescribeInstances\"\n\"ec2:DescribeInstanceTypes\"\n\"ec2:DescribeInstanceAttribute\"\n\"ecs:DescribeContainerInstances\"\n\"ec2:DescribeInstanceStatus\"\nTo pull container images stored in the ECR repositories:\n\"ecr:GetAuthorizationToken\"\n\"ecr:BatchCheckLayerAvailability\"\n\"ecr:GetDownloadUrlForLayer\"\n\"ecr:GetRepositoryPolicy\"\n\"ecr:DescribeRepositories\"\n\"ecr:ListImages\"\n\"ecr:DescribeImages\"\n\"ecr:BatchGetImage\"\n\"ecr:GetLifecyclePolicy\"\n\"ecr:GetLifecyclePolicyPreview\"\n\"ecr:ListTagsForResource\"\n\"ecr:DescribeImageScanFindings\"\n\nAdd any metadata tags if appropriate\nGive your new policy a name and click Create policy\nSelect your newly created permission policy to add to the user group and click Add permissions. Hint: you can find your new policy by ðŸ”searching in the filter box\n\nTo be able to use spot instances you will need to create an additional role.\n\nClick Roles under the IAM access management menu and click Create role\n\nSelect AWS service and EC2 under common use cases, click Next\nSearch for AmazonEC2SpotFleetTaggingRole select it and click Next\nAdd a role name, e.g.Â AmazonEC2SpotFleetRole and click Create role\n\nAWS batch uses Amazon Machine Images (AMIs) to initiate EC2 compute instances that will subsequently run your Nextflow processes. Nextflow tasks submitted to AWS Batch will run under the Amazon Elastic Container Service (ECS). ECS (not be be confused with EC2) uses a base Amazon ECS-optimised AMI (with docker pre-installed). Although Nextflow & Batch will control the CPU and memory resource request and allocation you need to ensure you base ECS AMI has sufficient EBS storage to hold any relevant input and working data files, such as sequence reads, indexes etc. You will also need to install the AWS CLI in the base ECS AMI to allow data movement to and from S3 buckets. To set all this up follow these steps:\n\nNavigate to the EC2 console menu\nClick Instances and then Launch Instances\nUnder â€˜quick startâ€™ click Browse more AMIs\nClick AWS Marketplace AMIs and search for ECS\nAt the time of writing amzn2-ami-ecs-hvm-2.0.20221025-x86_64-ebs was the most up to date ECS AMI. Select it\n\nSelect the t2.micro instance type\nSelect and relevant key pairs and network settings based on your setup (I would recommend at a minimum a private VPC and IP-restricted connections via a bastion instance)\nEnsure you have at least 30GiB storage ðŸ’¾ listed under â€˜Configure storageâ€™. Also change the storage type from gp2 to gp3 (for a performance boost at no additional cost - see Matt Vaughnâ€™s NextflowSummit 2022 talk ðŸ“½ï¸).\n\n\n\n\n\n\nNote\n\n\n\nFor some Nextflow processes your will need more than 30GiB of EBS storage. I would recommend making additional AMIs (based on this image) for these specific task and assigning them to specific Batch job queues, see later on.\n\n\nClick Launch instance ðŸš€\nSSH ðŸ’» into your new instance where you will need to install AWS CLI\nOnce connected run the following commands to install AWS CLI\ncd $HOME\nsudo yum install -y bzip2 wget\nwget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh -b -f -p $HOME/miniconda\n$HOME/miniconda/bin/conda install -c conda-forge -y awscli\nrm Miniconda3-latest-Linux-x86_64.sh\nTo verify the install was successful\n$ ./miniconda/bin/aws --version\naws-cli/1.19.79 Python/3.8.5 Linux/4.14.231-173.361.amzn2.x86_64 botocore/1.20.79\nUnder the Instances menu in the EC2 console select your relevant instance and click Actions, then Images and Templates, then Create Image\nGive your new image a name e.g.Â nextflow-30GiB-ecs-ami and click Create image\nðŸ“Take note of the AMI ID (not the name) that you just generated as you will need this later\n\n\n\n\n\n\n\nNote\n\n\n\nContrary to what is commonly written in other documentation you no longer need to expand your docker storage volume to match your allocated EBS storage size. The docker storage automatically expands on the Amazon 2 AMIs which are now default (unlike previous Amazon 1 AMIs).\n\n\nNow it is time to create your Batch environment which entails at least one compute environment and one job queue that Nextflow will submit processes to.\nNavigate to the Batch AWS console and click on Compute environments.\n\nClick Create and select Amazon Elastic Compute Cloud (Amazon EC2) as the compute environment.\nSelect Managed as the orchestration type and enter a suitable name for your new compute environment.\nIf this is your first time setting up a Batch environment AWS will create the relevant service role and instance role. Just ensure â€˜Create new roleâ€™ is selected. Alternatively, under â€˜Service roleâ€™ select AWSServiceRoleForBatch and under â€˜Instance Roleâ€™ select ecsInstanceRole. Click Next Page\nLeave Minimum and Desired vCPUs as 0. Maximum vCPUs controls the number of parallel vCPU tasks running in your compute environment. Increase or decrease this to an appropriate number based on your requirements.\nâ€˜Allowed instance typeâ€™ allows you to control the type instances that AWS is allowed to try and run your jobs on. Your CPU and memory requirements defined in your Nextflow config will apply a second tier of filtering (i.e.Â if you memory request is higher than an allowed instance type, obviously that instance type wonâ€™t be used). You can leave this as â€˜optimalâ€™ and AWS will attempt to find the best instance type match to your CPU and memory request.\n\n\n\n\n\n\nNote\n\n\n\nAWS is generally group multiple jobs onto the one large instance, however this can result in errors, particularly in I/O and/or network intensive tasks.\nIf you want to prevent AWS from grouping multiple jobs onto the one larger instance, then you need to specifically define smaller instances types, e.g.Â r6i.xlarge, r6i.2xlarge, to prevent AWS using super instances such as r6i.24xlarge r6i.32xlarge.\n\n\nTo use spot instance toggle the Use EC2 Spot instance button at the top and define your maximum cut off for on-demand price under â€˜Maximum % on-demand priceâ€™. Under â€˜spot fleet roleâ€™ you will also need to select the AmazonEC2SpotFleetRole role that you created earlier.\nUnder â€˜Additional configurationâ€™ you can define the allocation strategy\nBEST_FIT (default) AWS Batch selects an instance type that best fits the needs of the jobs with a preference for the lowest-cost instance type. If additional instances of the selected instance type arenâ€™t available, AWS Batch waits for the additional instances to be available. If there arenâ€™t enough instances available, or if the user is reaching the Amazon EC2 service quotas, then additional jobs donâ€™t run until currently running jobs are complete. This allocation strategy keeps costs lower but can limit scaling. If youâ€™re using Spot Fleets with BEST_FIT, the Spot Fleet IAM Role must be specified. BEST_FIT isnâ€™t supported when updating compute environments. For more information, see Updating compute environments.\nBEST_FIT_PROGRESSIVEAWS Batch selects additional instance types that are large enough to meet the requirements of the jobs in the queue. Instance types with a lower cost for each unit vCPU are preferred. If additional instances of the previously selected instance types arenâ€™t available, AWS Batch selects new instance types.\nSPOT_CAPACITY_OPTIMIZEDAWS Batch selects one or more instance types that are large enough to meet the requirements of the jobs in the queue. Instance types that are less likely to be interrupted are preferred. This allocation strategy is only available for Spot Instance compute resources.\nUnder â€˜EC2 configurationâ€™ click Add EC2 configuration and select Amazon Linux 2 as the image type and paste the AMI ID that you created earlier in the â€˜Image ID overrideâ€™ box.\n\nClick Next page and enter the appropriate network configuration for your VPC\nClick Next page, check your settings and then click Create compute environment\n\nStill within the Batch AWS console and click on Job queues.\n\nClick Create and select â€˜Amazon Elastic Compute Cloud (Amazon EC2)â€™ as the compute environment.\nEnter a suitable name for your new job queue (ðŸ“ take note of this name you will need it later)\nUnder â€˜Connected compute environmentsâ€™ select the compute environment that you just created\nClick Create job queue\n\nYou will want Nextflow to use an S3 bucket to store all the working files and results rather than an local connection.\n\nNavigate to the S3 service under the AWS management console and create a new private bucket in your relevant region.\nCreate a new folder within the bucket to serve as the Nextflow working directory (ðŸ“ take note of the S3 URI address as you will need this next)\n\nNow all you now need to do is set up your Nextflow config with the relevant details of your AWS setup. An example of initial config file is:\n//Select the awsbatch executor\nprocess.executor = 'awsbatch'\n\n//Name of the AWS Batch job queue that you just created\nprocess.queue = 'my-batch-queue'\n\n//Name of the docker container we want to use, you can also specify a separate docker container for each process\nprocess.container = 'quay.io/biocontainers/salmon'\n\n//region where we want to run this in\naws.region = 'ap-southeast-2'\n\n//Path to the aws cli tool you installed in your AMI\naws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'\n\n//S3 working directory that you just created\nworkDir = 's3://bucket_you_created/work/'\nThe last step is setting up your security credentials ðŸ” to allow Nextflow to securely communicate and submit jobs to AWS batch. The best approach is to install AWS CLI locally (or in a EC2 instance if submitting from EC2) https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\nThen run AWS configure and enter the relevant Key ID, Access Key, and Region when prompted. These are the keys that AWS provide when you generated your Nextflow programmatic user at the start of this guide. https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html\n\n\n\n\n\n\nWarning\n\n\n\nDO NOT store your credentials in your Nextflow configuration file like some tutorials suggest.\n\n\nðŸ—’ï¸Additional Notes:\n\nAWS batch jobs can take a few minutes to spin up, be patient before assuming you have something set up wrong\nIf you are using spot instances and your maximum % on-demand price is set too your jobs make take a long time to start or may not run at all\nYou can view the log stream of your jobs by clicking through the â€˜Runningâ€™ job numbers in the Batch dashboard and clicking the Log stream name - helpful to determine where a job is up to in a script\nThe Nextflow slack channel is a great place to raise any questions if you are still experiencing issues after following this setup guide, or want to experiment with some more advanced configurations and setups. https://www.nextflow.io/slack-invite.html\nlink to nextflow tips and tricks page"
  },
  {
    "objectID": "posts/aws-batch-ebs-autoscale/index.html",
    "href": "posts/aws-batch-ebs-autoscale/index.html",
    "title": "EBS Auto-scaling on AWS Batch",
    "section": "",
    "text": "![Photo by [Simon Goetz](https://unsplash.com/@slgoetz) on Unsplash](images/simon-goetz-feeredToXK4-unsplash.jpg)\nAnyone who has tried running bioinformatic pipelines on AWS batch with a workflow manager such as Nextflow will be well aware of the common error\nerror: No space left on device\nthat can plague a pipeline. Yes you can adjust your EBS allocation with specific AMI images or launch configurations and tailor them to specific tasks, but the dynamic nature of bioinformaticslogy means this will likely be ongoing cat ðŸˆ and mouse ðŸ game.\nYes Nextflow has the fantastic resume feature if your pipeline has already completed a large proportion of tasks, unfortunately though the config file is not reanalysed upon resume, so you cannot point to a new AMI with an increased EBS volume.\nThe solution? automatic scaling of your EBS volumes in real time. Essentially there is a script that resides within your AMI that contentiously monitors disk usage and just before you reach 100% it provisions a new EBS volumes mounting it directly to your running EC2 instance. You also get the added benefit of better EBS cost optimisation ðŸ’° as you no longer need to â€˜over provisionâ€™ your batch EC2 instances.\nThe setup can be split into two components, installing the auto-scaling scripts in your AMI and updating your Batch compute environments with appropriate permissions.\n\nSetup an appropriate IAM Role\n\nClick Create role under the IAM AWS console and select AWS service as the trusted entity type and EC2 as the use case, then click Next.\nCiick Create policy and select the JSON tab.\nPaste the following JSON code and click Next.\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"ec2:AttachVolume\",\n                \"ec2:DescribeVolumeStatus\",\n                \"ec2:DescribeVolumes\",\n                \"ec2:DescribeTags\",\n                \"ec2:ModifyInstanceAttribute\",\n                \"ec2:DescribeVolumeAttribute\",\n                \"ec2:CreateVolume\",\n                \"ec2:DeleteVolume\",\n                \"ec2:CreateTags\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n\nAdd any tags if applicable and click Next\nGive your policy a name e.g.Â amazon-ebs-autoscale-policy and click Create policy\nNow under the Add permission menu of your new IAM Role select your newly created policy, i.e.Â amazon-ebs-autoscale-policy and click Next\nGive your Role and name, e.g.Â amazon-ebs-autoscale-role and click Create role\nYou also need to add the amazon-ebs-autoscale-policy policy role to the ecsInstanceRolerole you use in your AWS Batch compute environments.\nUnder Roles in the AWS IAM console find and click the ecsInstanceRole role.\nClick Add permission and select Attach policies. Find/search for your new amazon-ebs-autoscale-policy, select it and click Attach policies.\n\n\n\nInstall the auto-scale scripts\n\nFetch or clone the amazon-ebs-autoscale repository to your local computer.\nEdit the EBS mount location to the volume that docker utilises by added the -m /var/lib/docker parameter to the install.sh command in the amazon-ebs-autoscale/templates/cloud-init-userdata.yamlfile\nSpecify the initial drive to use for the mountpoint to be /dev/xvdba with the -d parameter\nBy default the 100GiB volume will be initially provision at startup to change this add the -s parameter again to the the install.sh command in the amazon-ebs-autoscale/templates/cloud-init-userdata.yamlfile. For example to reduce it to the 30GB use -s 30\nthe runcmd: section should now look something like:\n\nruncmd:\n  - curl -s \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"/tmp/awscliv2.zip\"\n  - unzip -q /tmp/awscliv2.zip -d /tmp && /tmp/aws/install\n  - EBS_AUTOSCALE_VERSION=$(curl --silent \"https://api.github.com/repos/awslabs/amazon-ebs-autoscale/releases/latest\" | jq -r .tag_name)\n  - cd /opt && git clone https://github.com/awslabs/amazon-ebs-autoscale.git\n  - cd /opt/amazon-ebs-autoscale && git checkout $EBS_AUTOSCALE_VERSION\n  - sh /opt/amazon-ebs-autoscale/install.sh -m /var/lib/docker -d /dev/xvdba -s 30 2>&1 > /var/log/ebs-autoscale-install.log\n\nInstall the amazon-ebs-autoscale scripts with your defined paramaters into your chosen AMI you can use the aws ec2 run-instance command from the aws-cli. An example of launching your chosen AMI and installing the amazon-ebs-autoscale scripts is\n\naws ec2 run-instances --image-id YOUR-AMI-ID \\\n  --key-name YOUR-KEY-PAIR-NAME \\\n  --subnet-id YOUR-SUBNET-ID \\\n  --user-data file://./templates/cloud-init-userdata.yaml \\\n  --count 1 \\\n  --security-group-ids YOUR-SECURITY-GROUP-ID \\\n  --instance-type t2.micro \\\n  --iam-instance-profile Name=amazon-ebs-autoscale-role\n\nRunning this from your command line will launch a EC2 instance which you can then save as a new AMI with an appropriate name. (see my Nextflow on AWS Batch blog post for details on how to save AMIs)"
  }
]