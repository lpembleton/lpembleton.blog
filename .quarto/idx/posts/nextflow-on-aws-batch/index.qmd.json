{"title":"Nextflow on AWS Batch","markdown":{"yaml":{"title":"Nextflow on AWS Batch","description":"An introductory guide to setting up Nextflow with AWS Batch","author":"LW Pembleton","date":"25 11 2022","categories":["Nextflow","AWS","Batch"],"image":"images/jenessaa-lu-gTKFunYTVds-unsplash.jpg","draft":false},"headingText":"IAM Setup","containsRefs":false,"markdown":"\n\n![~Photo¬†by¬†[Jenessaa¬†Lu](https://unsplash.com/@jenessaa?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)¬†on¬†Unsplash~](images/jenessaa-lu-gTKFunYTVds-unsplash.jpg)\n\nThe following is a general guide on how to set up Nextflow with AWS batch as the compute environment. I would highly recommend that you use your local environment or at least a smaller test dataset for pipeline development, transferring to AWS batch when in a working production state.\n\nAlthough Gandalf üßô trims his beard more often than Amazon updates their AWS user interface, I cannot guarantee the included menu screenshots will look the same on your system. However, hopefully they will still provide sufficient information to determine the appropriate settings and options. Reach out if you feel I need to update this guide.\n\n\nFirstly you need to create a new [IAM](https://aws.amazon.com/iam/getting-started/?nc=sn&loc=3) with more appropriate permissions tailored to the requirements listed in [Nextflow documentation](https://www.nextflow.io/docs/latest/awscloud.html). It is strongly recommended that do not use your root account to run Nextflow pipelines.\n\n1.  Open the IAM management console on AWS and add a new user\n\n2.  Enter an appropriate user name for example 'Nextflow-access'. Under access type, select *programmatic access*\n\n    ![](images/aws-iam-add-user.png)\n\n3.  Next you need to create a user group for the new user to sit within. Generally, on AWS you will apply permissions to a user group rather than a specific user. Additionally, this allows you to set up multiple separate people within the 'Nextflow group'. Again, enter an appropriate name and click **Create group**\n\n4.  Add any metadata tags if appropriate\n\n5.  Click **Create user**. You should be greeted with a new page that includes a Access Key ID and SCA (üìù *take note of these keys as you will need them towards the end of this guide*)\n\nNow that you have your new user and Nextflow group you will need to apply the required permissions.\n\n1.  From the IAM user panel click **User groups** select your recently created 'nextflow' group, and under the **permissions** menu click on the **Attach policy** button\n\n    ![](images/attach-policies.png)\n\n2.  Click **Create policy**\n\n    ![](images/create-policy.png)\n\n3.  Use the visual editor to add all the required permissions\n\n    ![](images/create-policy-permissions.png)\n\n    [Minimal permissions policies](https://www.nextflow.io/docs/latest/awscloud.html) to be attached to the AWS account used by Nextflow are:\n\n    -   To interface AWS Batch:\n\n            \"batch:DescribeJobQueues\"\n            \"batch:CancelJob\"\n            \"batch:SubmitJob\"\n            \"batch:ListJobs\"\n            \"batch:DescribeComputeEnvironments\"\n            \"batch:TerminateJob\"\n            \"batch:DescribeJobs\"\n            \"batch:RegisterJobDefinition\"\n            \"batch:DescribeJobDefinitions\"\n\n    -   To be able to see the [EC2](https://aws.amazon.com/ec2/) instances:\n\n            \"ecs:DescribeTasks\"\n            \"ec2:DescribeInstances\"\n            \"ec2:DescribeInstanceTypes\"\n            \"ec2:DescribeInstanceAttribute\"\n            \"ecs:DescribeContainerInstances\"\n            \"ec2:DescribeInstanceStatus\"\n\n    -   To pull container images stored in the [ECR](https://aws.amazon.com/ecr/) repositories:\n\n            \"ecr:GetAuthorizationToken\"\n            \"ecr:BatchCheckLayerAvailability\"\n            \"ecr:GetDownloadUrlForLayer\"\n            \"ecr:GetRepositoryPolicy\"\n            \"ecr:DescribeRepositories\"\n            \"ecr:ListImages\"\n            \"ecr:DescribeImages\"\n            \"ecr:BatchGetImage\"\n            \"ecr:GetLifecyclePolicy\"\n            \"ecr:GetLifecyclePolicyPreview\"\n            \"ecr:ListTagsForResource\"\n            \"ecr:DescribeImageScanFindings\"\n\n4.  You also need to [add permissions for S3](https://www.nextflow.io/docs/latest/awscloud.html#s3-policies) so that nextlflow can pull input data and publish results. Still using the visual editor select **S3** as the service and then select the **All S3 actions (s3:\\*)** check box under actions. You may get notifications of other 'dependency' type permissions that are required, follow the instructions to add these as well.\n\n    ![](images/s3-policy.png)\n\n5.  Add any metadata tags if appropriate\n\n6.  Give your new policy a name and click **Create policy**\n\n7.  Select your newly created permission policy to add to the user group and click **Add permissions.** *Hint: you can find your new policy by* üîç*searching in the filter box*\n\nTo be able to use [spot instances](https://aws.amazon.com/ec2/spot/) you will need to create an additional role.\n\n1.  Click **Roles** under the IAM access management menu and click **Create role**\n\n    ![](images/create-role.png)\n\n2.  Select **AWS service** and **EC2** under common use cases, click **Next**\n\n3.  Search for **AmazonEC2SpotFleetTaggingRole** select it and click **Next**\n\n4.  Add a role name, e.g. *AmazonEC2SpotFleetRole* and click **Create role**\n\n## Custom Nextflow AMI\n\nAWS batch uses Amazon Machine Images ([AMIs](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html)) to initiate EC2 compute instances that will subsequently run your Nextflow processes. Nextflow tasks submitted to AWS Batch will run under the Amazon Elastic Container Service ([ECS](https://aws.amazon.com/ecs/)). ECS (*not to be confused with EC2*) uses a base Amazon ECS-optimised AMI (with docker pre-installed). Although Nextflow & Batch will control the CPU and memory resource request and allocation you need to ensure you base ECS AMI has sufficient [EBS](https://aws.amazon.com/ebs/) storage to hold any relevant input and working data files, such as sequence reads, indexes etc. You will also need to install the AWS CLI in the base ECS AMI to allow data movement to and from S3 buckets. To set all this up follow these steps:\n\n1.  Navigate to the EC2 console menu\n\n2.  Click **Instances** and then **Launch Instances**\n\n3.  Under 'quick start' click **Browse more AMIs**\n\n4.  Click **AWS Marketplace AMIs** and search for **ECS**\n\n5.  At the time of writing **amzn2-ami-ecs-hvm-2.0.20221025-x86_64-ebs** was the most up-to-date ECS AMI. Select it\n\n    ![](images/amsn2-ecs-marketplace.png)\n\n6.  Select the t2.micro instance type\n\n7.  Select and relevant key pairs and network settings based on your setup (I would recommend at a minimum a private VPC and IP-restricted connections via a bastion instance)\n\n8.  Ensure you have at least 30GiB storage üíæ listed under 'Configure storage'. Also change the storage type from gp2 to **gp3** (for a performance boost at no additional cost - see [Matt Vaughn's NextflowSummit 2022 talk](https://youtu.be/E5XGxQvqZLs?list=PLPZ8WHdZGxmUdAJlHowo7zL2pN3x97d32&t=459) üìΩÔ∏è).\n\n    ::: callout-note\n    For some Nextflow processes your will need more than 30GiB of EBS storage. I would recommend making additional AMIs (based on this image) for these specific tasks and assigning them to specific Batch job queues, see later on.\n    :::\n\n9.  Click **Launch instance** üöÄ\n\n10. SSH üíª into your new instance where you will need to install AWS CLI\n\n11. Once connected run the following commands to install AWS CLI\n\n        cd $HOME\n        sudo yum install -y bzip2 wget\n        wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n        bash Miniconda3-latest-Linux-x86_64.sh -b -f -p $HOME/miniconda\n        $HOME/miniconda/bin/conda install -c conda-forge -y awscli\n        rm Miniconda3-latest-Linux-x86_64.sh\n\n12. To verify the install was successful\n\n        $ ./miniconda/bin/aws --version\n        aws-cli/1.19.79 Python/3.8.5 Linux/4.14.231-173.361.amzn2.x86_64 botocore/1.20.79\n\n13. Under the **Instances** menu in the EC2 console select your relevant instance and click **Actions,** then **Images and Templates**, then **Create Image**\n\n14. Give your new image a name e.g. *nextflow-30GiB-ecs-ami* and click **Create image**\n\n15. üìùTake note of the AMI ID (not the name) that you just generated as you will need this later\n\n::: callout-note\nContrary to what is commonly written in other documentation you no longer need to expand your docker üêãstorage volume to match your allocated EBS storage size. The docker storage automatically expands on the Amazon 2 AMIs which are now default (unlike previous Amazon 1 AMIs).\n:::\n\n## Batch Environment\n\nNow it is time to create your Batch environment which entails at least one compute environment and one job queue that Nextflow will submit processes to.\n\nNavigate to the Batch AWS console and click on **Compute environments**.\n\n1.  Click **Create** and select **Amazon Elastic Compute Cloud (Amazon EC2)** as the compute environment.\n\n2.  Select **Managed** as the orchestration type and enter a suitable name for your new compute environment.\n\n3.  If this is your first time setting up a Batch environment AWS will create the relevant service role and instance role. Just ensure '*Create new role*' is selected. Alternatively, under '*Service role*' select **AWSServiceRoleForBatch** and under '*Instance Role*' select **ecsInstanceRole**. Click **Next Page**\n\n4.  Leave Minimum and Desired vCPUs as 0. Maximum vCPUs controls the allowed maximum number of parallel vCPU tasks that can run in your compute environment at any one time. Increase or decrease this to an appropriate number based on your requirements.\n\n5.  'Allowed instance type' allows you to control the type of instances that AWS is allowed to try and run your jobs on. Your CPU and memory requirements defined in your Nextflow config will apply a second tier of filtering (i.e. if your memory request is higher than an allowed instance type, obviously that instance type won't be used). You can leave this as 'optimal' and AWS will attempt to find the best instance type match to your CPU and memory request.\n\n    ::: callout-note\n    AWS will generally group multiple jobs onto the one large instance, however, this can result in errors, particularly from noisy neighbors, and I/O and/or network intensive tasks.\n\n    If you want to prevent AWS from grouping multiple jobs onto the one larger instance, then you need to specifically define smaller instances types, e.g. r6i.xlarge, r6i.2xlarge, to prevent AWS using super instances such as r6i.24xlarge r6i.32xlarge.\n    :::\n\n6.  To use spot instances toggle the **Use EC2 Spot instances** button at the top and define your maximum cut-off for on-demand price under 'Maximum % on-demand price'. Under 'spot fleet role' you will also need to select the **AmazonEC2SpotFleetRole** role that you created earlier.\n\n7.  Under 'Additional configuration' you can define the allocation strategy\n\n    `BEST_FIT` (default) AWS Batch selects an instance type that best fits the needs of the jobs with a preference for the lowest-cost instance type. If additional instances of the selected instance type aren't available, AWS Batch waits for the additional instances to be available. If there aren't enough instances available, or if the user is reaching the [Amazon EC2 service quotas](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-resource-limits.html), then additional jobs don't run until currently running jobs are complete. This allocation strategy keeps costs lower but can limit scaling. If you're using Spot Fleets with `BEST_FIT`, the Spot Fleet IAM Role must be specified. `BEST_FIT` isn't supported when updating compute environments. For more information, see [Updating compute environments](https://docs.aws.amazon.com/batch/latest/userguide/updating-compute-environments.html).\n\n    `BEST_FIT_PROGRESSIVE`AWS Batch selects additional instance types that are large enough to meet the requirements of the jobs in the queue. Instance types with a lower cost for each unit vCPU are preferred. If additional instances of the previously selected instance types aren't available, AWS Batch selects new instance types.\n\n    `SPOT_CAPACITY_OPTIMIZED`AWS Batch selects one or more instance types that are large enough to meet the requirements of the jobs in the queue. Instance types that are less likely to be interrupted are preferred. This allocation strategy is only available for Spot Instance compute resources.\n\n8.  Under 'EC2 configuration' click **Add EC2 configuration** and select **Amazon Linux 2** as the image type and paste the AMI ID that you created earlier in the 'Image ID override' box.\n\n    ![](images/instance-config.png)\n\n9.  Click **Next page** and enter the appropriate network configuration for your VPC\n\n10. Click **Next page,** check your settings and then click **Create compute environment**\n\nStill within the Batch AWS console and click on **Job queues**.\n\n1.  Click **Create** and select 'Amazon Elastic Compute Cloud (Amazon EC2)' as the compute environment.\n2.  Enter a suitable name for your new job queue (üìù *take note of this name you will need it later*)\n3.  Under 'Connected compute environments' select the compute environment that you just created\n4.  Click **Create job queue**\n\nYou will want Nextflow to use an S3 bucket to store all the working files and results rather than a local connection.\n\n1.  Navigate to the S3 service under the AWS management console and create a new private bucket in your relevant region.\n2.  Create a new folder within the bucket to serve as the Nextflow working directory (üìù take note of the S3 URI address as you will need this next)\n\n## Nextflow Config\n\nNow all you now need to do is set up your Nextflow config with the relevant details of your AWS setup. An example of initial config file is:\n\n    //Select the awsbatch executor\n    process.executor = 'awsbatch'\n\n    //Name of the AWS Batch job queue that you just created\n    process.queue = 'my-batch-queue'\n\n    //region where we want to run this in\n    aws.region = 'ap-southeast-2'\n\n    //Path to the aws cli tool you installed in your AMI\n    aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'\n\n    //S3 working directory that you just created\n    workDir = 's3://bucket_you_created/work/'\n\nThe last step is setting up your security credentials üîê to allow Nextflow to securely communicate and submit jobs to AWS batch. The best approach is to [install AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html) locally (or in a EC2 instance if [submitting from EC2](https://www.nextflow.io/docs/latest/awscloud.html#pipeline-execution)).\n\nThen [run](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html) `AWS configure` and enter the relevant Key ID, Access Key, and Region when prompted. These are the keys that AWS provided when you generated your Nextflow programmatic user at the start of this guide.\n\n::: callout-warning\n**DO NOT** store your credentials in your Nextflow configuration file as some tutorials suggest.\n:::\n\n## üóíÔ∏èAdditional Notes:\n\n-   AWS batch jobs can take a few minutes to spin up, be patient before assuming you have set something up wrong\n\n-   If you are using spot instances and your maximum % on-demand price is set too low your jobs make take a long time to start or may not run at all\n\n-   You can view the log stream of your jobs by clicking through the 'Running' job numbers in the Batch dashboard and clicking the **Log stream name -** helpful to determine where a job is up to in a script\n\n-   The [Nextflow slack channel](https://www.nextflow.io/slack-invite.html) is a great place to raise any questions if you are still experiencing issues after following this setup guide, or want to experiment with some more advanced configurations and setups.\n\n## Common errors\n\nBelow are a list of common errors. Although the proposed solution has been demonstrated to work it may not always work in your specific scenario.\n\n`Task failed to start - CannotPullContainerError: context canceled`\n\nProposed solution: Increase your AMI EBS storage.\n","srcMarkdownNoYaml":"\n\n![~Photo¬†by¬†[Jenessaa¬†Lu](https://unsplash.com/@jenessaa?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)¬†on¬†Unsplash~](images/jenessaa-lu-gTKFunYTVds-unsplash.jpg)\n\nThe following is a general guide on how to set up Nextflow with AWS batch as the compute environment. I would highly recommend that you use your local environment or at least a smaller test dataset for pipeline development, transferring to AWS batch when in a working production state.\n\nAlthough Gandalf üßô trims his beard more often than Amazon updates their AWS user interface, I cannot guarantee the included menu screenshots will look the same on your system. However, hopefully they will still provide sufficient information to determine the appropriate settings and options. Reach out if you feel I need to update this guide.\n\n## IAM Setup\n\nFirstly you need to create a new [IAM](https://aws.amazon.com/iam/getting-started/?nc=sn&loc=3) with more appropriate permissions tailored to the requirements listed in [Nextflow documentation](https://www.nextflow.io/docs/latest/awscloud.html). It is strongly recommended that do not use your root account to run Nextflow pipelines.\n\n1.  Open the IAM management console on AWS and add a new user\n\n2.  Enter an appropriate user name for example 'Nextflow-access'. Under access type, select *programmatic access*\n\n    ![](images/aws-iam-add-user.png)\n\n3.  Next you need to create a user group for the new user to sit within. Generally, on AWS you will apply permissions to a user group rather than a specific user. Additionally, this allows you to set up multiple separate people within the 'Nextflow group'. Again, enter an appropriate name and click **Create group**\n\n4.  Add any metadata tags if appropriate\n\n5.  Click **Create user**. You should be greeted with a new page that includes a Access Key ID and SCA (üìù *take note of these keys as you will need them towards the end of this guide*)\n\nNow that you have your new user and Nextflow group you will need to apply the required permissions.\n\n1.  From the IAM user panel click **User groups** select your recently created 'nextflow' group, and under the **permissions** menu click on the **Attach policy** button\n\n    ![](images/attach-policies.png)\n\n2.  Click **Create policy**\n\n    ![](images/create-policy.png)\n\n3.  Use the visual editor to add all the required permissions\n\n    ![](images/create-policy-permissions.png)\n\n    [Minimal permissions policies](https://www.nextflow.io/docs/latest/awscloud.html) to be attached to the AWS account used by Nextflow are:\n\n    -   To interface AWS Batch:\n\n            \"batch:DescribeJobQueues\"\n            \"batch:CancelJob\"\n            \"batch:SubmitJob\"\n            \"batch:ListJobs\"\n            \"batch:DescribeComputeEnvironments\"\n            \"batch:TerminateJob\"\n            \"batch:DescribeJobs\"\n            \"batch:RegisterJobDefinition\"\n            \"batch:DescribeJobDefinitions\"\n\n    -   To be able to see the [EC2](https://aws.amazon.com/ec2/) instances:\n\n            \"ecs:DescribeTasks\"\n            \"ec2:DescribeInstances\"\n            \"ec2:DescribeInstanceTypes\"\n            \"ec2:DescribeInstanceAttribute\"\n            \"ecs:DescribeContainerInstances\"\n            \"ec2:DescribeInstanceStatus\"\n\n    -   To pull container images stored in the [ECR](https://aws.amazon.com/ecr/) repositories:\n\n            \"ecr:GetAuthorizationToken\"\n            \"ecr:BatchCheckLayerAvailability\"\n            \"ecr:GetDownloadUrlForLayer\"\n            \"ecr:GetRepositoryPolicy\"\n            \"ecr:DescribeRepositories\"\n            \"ecr:ListImages\"\n            \"ecr:DescribeImages\"\n            \"ecr:BatchGetImage\"\n            \"ecr:GetLifecyclePolicy\"\n            \"ecr:GetLifecyclePolicyPreview\"\n            \"ecr:ListTagsForResource\"\n            \"ecr:DescribeImageScanFindings\"\n\n4.  You also need to [add permissions for S3](https://www.nextflow.io/docs/latest/awscloud.html#s3-policies) so that nextlflow can pull input data and publish results. Still using the visual editor select **S3** as the service and then select the **All S3 actions (s3:\\*)** check box under actions. You may get notifications of other 'dependency' type permissions that are required, follow the instructions to add these as well.\n\n    ![](images/s3-policy.png)\n\n5.  Add any metadata tags if appropriate\n\n6.  Give your new policy a name and click **Create policy**\n\n7.  Select your newly created permission policy to add to the user group and click **Add permissions.** *Hint: you can find your new policy by* üîç*searching in the filter box*\n\nTo be able to use [spot instances](https://aws.amazon.com/ec2/spot/) you will need to create an additional role.\n\n1.  Click **Roles** under the IAM access management menu and click **Create role**\n\n    ![](images/create-role.png)\n\n2.  Select **AWS service** and **EC2** under common use cases, click **Next**\n\n3.  Search for **AmazonEC2SpotFleetTaggingRole** select it and click **Next**\n\n4.  Add a role name, e.g. *AmazonEC2SpotFleetRole* and click **Create role**\n\n## Custom Nextflow AMI\n\nAWS batch uses Amazon Machine Images ([AMIs](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html)) to initiate EC2 compute instances that will subsequently run your Nextflow processes. Nextflow tasks submitted to AWS Batch will run under the Amazon Elastic Container Service ([ECS](https://aws.amazon.com/ecs/)). ECS (*not to be confused with EC2*) uses a base Amazon ECS-optimised AMI (with docker pre-installed). Although Nextflow & Batch will control the CPU and memory resource request and allocation you need to ensure you base ECS AMI has sufficient [EBS](https://aws.amazon.com/ebs/) storage to hold any relevant input and working data files, such as sequence reads, indexes etc. You will also need to install the AWS CLI in the base ECS AMI to allow data movement to and from S3 buckets. To set all this up follow these steps:\n\n1.  Navigate to the EC2 console menu\n\n2.  Click **Instances** and then **Launch Instances**\n\n3.  Under 'quick start' click **Browse more AMIs**\n\n4.  Click **AWS Marketplace AMIs** and search for **ECS**\n\n5.  At the time of writing **amzn2-ami-ecs-hvm-2.0.20221025-x86_64-ebs** was the most up-to-date ECS AMI. Select it\n\n    ![](images/amsn2-ecs-marketplace.png)\n\n6.  Select the t2.micro instance type\n\n7.  Select and relevant key pairs and network settings based on your setup (I would recommend at a minimum a private VPC and IP-restricted connections via a bastion instance)\n\n8.  Ensure you have at least 30GiB storage üíæ listed under 'Configure storage'. Also change the storage type from gp2 to **gp3** (for a performance boost at no additional cost - see [Matt Vaughn's NextflowSummit 2022 talk](https://youtu.be/E5XGxQvqZLs?list=PLPZ8WHdZGxmUdAJlHowo7zL2pN3x97d32&t=459) üìΩÔ∏è).\n\n    ::: callout-note\n    For some Nextflow processes your will need more than 30GiB of EBS storage. I would recommend making additional AMIs (based on this image) for these specific tasks and assigning them to specific Batch job queues, see later on.\n    :::\n\n9.  Click **Launch instance** üöÄ\n\n10. SSH üíª into your new instance where you will need to install AWS CLI\n\n11. Once connected run the following commands to install AWS CLI\n\n        cd $HOME\n        sudo yum install -y bzip2 wget\n        wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n        bash Miniconda3-latest-Linux-x86_64.sh -b -f -p $HOME/miniconda\n        $HOME/miniconda/bin/conda install -c conda-forge -y awscli\n        rm Miniconda3-latest-Linux-x86_64.sh\n\n12. To verify the install was successful\n\n        $ ./miniconda/bin/aws --version\n        aws-cli/1.19.79 Python/3.8.5 Linux/4.14.231-173.361.amzn2.x86_64 botocore/1.20.79\n\n13. Under the **Instances** menu in the EC2 console select your relevant instance and click **Actions,** then **Images and Templates**, then **Create Image**\n\n14. Give your new image a name e.g. *nextflow-30GiB-ecs-ami* and click **Create image**\n\n15. üìùTake note of the AMI ID (not the name) that you just generated as you will need this later\n\n::: callout-note\nContrary to what is commonly written in other documentation you no longer need to expand your docker üêãstorage volume to match your allocated EBS storage size. The docker storage automatically expands on the Amazon 2 AMIs which are now default (unlike previous Amazon 1 AMIs).\n:::\n\n## Batch Environment\n\nNow it is time to create your Batch environment which entails at least one compute environment and one job queue that Nextflow will submit processes to.\n\nNavigate to the Batch AWS console and click on **Compute environments**.\n\n1.  Click **Create** and select **Amazon Elastic Compute Cloud (Amazon EC2)** as the compute environment.\n\n2.  Select **Managed** as the orchestration type and enter a suitable name for your new compute environment.\n\n3.  If this is your first time setting up a Batch environment AWS will create the relevant service role and instance role. Just ensure '*Create new role*' is selected. Alternatively, under '*Service role*' select **AWSServiceRoleForBatch** and under '*Instance Role*' select **ecsInstanceRole**. Click **Next Page**\n\n4.  Leave Minimum and Desired vCPUs as 0. Maximum vCPUs controls the allowed maximum number of parallel vCPU tasks that can run in your compute environment at any one time. Increase or decrease this to an appropriate number based on your requirements.\n\n5.  'Allowed instance type' allows you to control the type of instances that AWS is allowed to try and run your jobs on. Your CPU and memory requirements defined in your Nextflow config will apply a second tier of filtering (i.e. if your memory request is higher than an allowed instance type, obviously that instance type won't be used). You can leave this as 'optimal' and AWS will attempt to find the best instance type match to your CPU and memory request.\n\n    ::: callout-note\n    AWS will generally group multiple jobs onto the one large instance, however, this can result in errors, particularly from noisy neighbors, and I/O and/or network intensive tasks.\n\n    If you want to prevent AWS from grouping multiple jobs onto the one larger instance, then you need to specifically define smaller instances types, e.g. r6i.xlarge, r6i.2xlarge, to prevent AWS using super instances such as r6i.24xlarge r6i.32xlarge.\n    :::\n\n6.  To use spot instances toggle the **Use EC2 Spot instances** button at the top and define your maximum cut-off for on-demand price under 'Maximum % on-demand price'. Under 'spot fleet role' you will also need to select the **AmazonEC2SpotFleetRole** role that you created earlier.\n\n7.  Under 'Additional configuration' you can define the allocation strategy\n\n    `BEST_FIT` (default) AWS Batch selects an instance type that best fits the needs of the jobs with a preference for the lowest-cost instance type. If additional instances of the selected instance type aren't available, AWS Batch waits for the additional instances to be available. If there aren't enough instances available, or if the user is reaching the [Amazon EC2 service quotas](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-resource-limits.html), then additional jobs don't run until currently running jobs are complete. This allocation strategy keeps costs lower but can limit scaling. If you're using Spot Fleets with `BEST_FIT`, the Spot Fleet IAM Role must be specified. `BEST_FIT` isn't supported when updating compute environments. For more information, see [Updating compute environments](https://docs.aws.amazon.com/batch/latest/userguide/updating-compute-environments.html).\n\n    `BEST_FIT_PROGRESSIVE`AWS Batch selects additional instance types that are large enough to meet the requirements of the jobs in the queue. Instance types with a lower cost for each unit vCPU are preferred. If additional instances of the previously selected instance types aren't available, AWS Batch selects new instance types.\n\n    `SPOT_CAPACITY_OPTIMIZED`AWS Batch selects one or more instance types that are large enough to meet the requirements of the jobs in the queue. Instance types that are less likely to be interrupted are preferred. This allocation strategy is only available for Spot Instance compute resources.\n\n8.  Under 'EC2 configuration' click **Add EC2 configuration** and select **Amazon Linux 2** as the image type and paste the AMI ID that you created earlier in the 'Image ID override' box.\n\n    ![](images/instance-config.png)\n\n9.  Click **Next page** and enter the appropriate network configuration for your VPC\n\n10. Click **Next page,** check your settings and then click **Create compute environment**\n\nStill within the Batch AWS console and click on **Job queues**.\n\n1.  Click **Create** and select 'Amazon Elastic Compute Cloud (Amazon EC2)' as the compute environment.\n2.  Enter a suitable name for your new job queue (üìù *take note of this name you will need it later*)\n3.  Under 'Connected compute environments' select the compute environment that you just created\n4.  Click **Create job queue**\n\nYou will want Nextflow to use an S3 bucket to store all the working files and results rather than a local connection.\n\n1.  Navigate to the S3 service under the AWS management console and create a new private bucket in your relevant region.\n2.  Create a new folder within the bucket to serve as the Nextflow working directory (üìù take note of the S3 URI address as you will need this next)\n\n## Nextflow Config\n\nNow all you now need to do is set up your Nextflow config with the relevant details of your AWS setup. An example of initial config file is:\n\n    //Select the awsbatch executor\n    process.executor = 'awsbatch'\n\n    //Name of the AWS Batch job queue that you just created\n    process.queue = 'my-batch-queue'\n\n    //region where we want to run this in\n    aws.region = 'ap-southeast-2'\n\n    //Path to the aws cli tool you installed in your AMI\n    aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'\n\n    //S3 working directory that you just created\n    workDir = 's3://bucket_you_created/work/'\n\nThe last step is setting up your security credentials üîê to allow Nextflow to securely communicate and submit jobs to AWS batch. The best approach is to [install AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html) locally (or in a EC2 instance if [submitting from EC2](https://www.nextflow.io/docs/latest/awscloud.html#pipeline-execution)).\n\nThen [run](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html) `AWS configure` and enter the relevant Key ID, Access Key, and Region when prompted. These are the keys that AWS provided when you generated your Nextflow programmatic user at the start of this guide.\n\n::: callout-warning\n**DO NOT** store your credentials in your Nextflow configuration file as some tutorials suggest.\n:::\n\n## üóíÔ∏èAdditional Notes:\n\n-   AWS batch jobs can take a few minutes to spin up, be patient before assuming you have set something up wrong\n\n-   If you are using spot instances and your maximum % on-demand price is set too low your jobs make take a long time to start or may not run at all\n\n-   You can view the log stream of your jobs by clicking through the 'Running' job numbers in the Batch dashboard and clicking the **Log stream name -** helpful to determine where a job is up to in a script\n\n-   The [Nextflow slack channel](https://www.nextflow.io/slack-invite.html) is a great place to raise any questions if you are still experiencing issues after following this setup guide, or want to experiment with some more advanced configurations and setups.\n\n## Common errors\n\nBelow are a list of common errors. Although the proposed solution has been demonstrated to work it may not always work in your specific scenario.\n\n`Task failed to start - CannotPullContainerError: context canceled`\n\nProposed solution: Increase your AMI EBS storage.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","editor":"visual","theme":["../../theme.scss"],"mainfont":"Nunito","toc-title":"On this page","toc-location":"left","title-block-banner":true,"comments":{"giscus":{"repo":"lpembleton/lpembleton.blog","category":"Blog"}},"title":"Nextflow on AWS Batch","description":"An introductory guide to setting up Nextflow with AWS Batch","author":"LW Pembleton","date":"25 11 2022","categories":["Nextflow","AWS","Batch"],"image":"images/jenessaa-lu-gTKFunYTVds-unsplash.jpg","draft":false},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}