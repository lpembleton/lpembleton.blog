{
  "hash": "0541236468726d2a6b6d852c1efe1b1a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Building With Resume\"\ndescription: \"A guide to using the resume function in Nextflow to modularly build pipelines\"\nauthor: \"LW Pembleton\"\ndate: 13 11 2024\ncategories: [Nextflow, Bioinformatics]\nimage: images/james-wainscoat-hjmED1qivmc-unsplash.jpg\ndraft: false\nhighlight-style: ayu\n---\n\n\n![\\~Photo by [James Wainscoat](https://unsplash.com/@tumbao1949) on Unsplash\\~](images/james-wainscoat-hjmED1qivmc-unsplash.jpg)\n\n## Build With Resume\n\nThe [resume](https://www.nextflow.io/docs/latest/cache-and-resume.html) feature has to be one of the most powerful tools in [Nextflow](https://www.nextflow.io). It not only lets you recover an interrupted pipeline without redoing the whole thing, but it’s also super handy for writing and testing pipelines. \"Build with resume\" is my go-to approach for developing pipelines. I build them one process at a time, check channel outputs and published files, then add the next process and run it again using the -resume flag. This way, I can pick up from the last process instead of starting from scratch every time, and progressively add 🏗️ and check ✅ each process.\n\nSo, I thought I’d share a step-by-step example for anyone interested. You can find all the files in my [GitHub repository](https://github.com/lpembleton/build-with-resume).\n\nRather than using some irrelevant “Hello World” 👋 example, I’m going with a trimmed-down read mapping 🧬 and variant-calling pipeline. Hopefully, this feels a bit more meaningful!\n\n::: callout-note\nThis example assumes you already have Docker and Nextflow set up on your system.\n:::\n\nAssuming you have downloaded the GitHub repo you will have the relevant process modules and associated config file. What we are going to therefore focus on is the workflow. So lets get going 🛫\n\n### Step 1: Read in Input Files\n\nWe’ll start by reading a CSV samplesheet to define our input. When I first starting learning Nextflow I really struggled with the fact that all examples would just scan directories for FASTQ files. It just didn't compute 🤔 for me — I have always use samplesheets or lists as my input. Seriously, how often are all your samples in one folder, and don't we usually want some metadata with each sample? So, for those out there like me let’s go with a CSV samplesheet format (just like most mature Nextflow pipelines out there). We’ll use the [splitCsv](https://www.nextflow.io/docs/latest/reference/operator.html#splitcsv) operator and [map](https://www.nextflow.io/docs/latest/reference/operator.html#map) to split each row into a tuple containing the sample ID and read file paths, then set that as a channel called `input_reads`.\n\nHere’s what it looks like 👇\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#test comment\n```\n:::\n\n\n```default\n// Check mandatory parameters\nif (params.input) { csv_file = file(params.input) } else { exit 1, 'Input samplesheet not specified!' }\nif (params.reference == null) error \"Please specify a reference genome fasta file with --reference\"\n\ndef reference =  file(params.reference)\n\n/*\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    IMPORT LOCAL MODULES\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n*/\n\ninclude { FASTP } from './modules/local/fastp'\ninclude { SAMTOOLS_FAIDX } from './modules/local/samtools_faidx'\ninclude { BWA_INDEX } from './modules/local/bwa_index'\ninclude { BWA_MEM } from './modules/local/bwa_mem'\ninclude { BCFTOOLS_CALL } from './modules/local/bcftools_call'\n\n\nworkflow {\n\n    // Read in samplesheet and convert into input sample channel\n    Channel.fromPath(params.input) \\\n        | splitCsv(header:true) \\\n        | map { row-> tuple(row.sample_id, file(row.fastq_1), file(row.fastq_2)) } \\\n        | set {input_reads}\n\n}\n```\n\nNow, we could run this first step, but we wouldn’t see any output. Let’s spice it up and add a view() statement to check out 👀 our new input_reads channel:\n\n```         \n// Check mandatory parameters\nif (params.input) { csv_file = file(params.input) } else { exit 1, 'Input samplesheet not specified!' }\nif (params.reference == null) error \"Please specify a reference genome fasta file with --reference\"\n\ndef reference =  file(params.reference)\n\n/*\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    IMPORT LOCAL MODULES\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n*/\n\ninclude { FASTP } from './modules/local/fastp'\ninclude { SAMTOOLS_FAIDX } from './modules/local/samtools_faidx'\ninclude { BWA_INDEX } from './modules/local/bwa_index'\ninclude { BWA_MEM } from './modules/local/bwa_mem'\ninclude { BCFTOOLS_CALL } from './modules/local/bcftools_call'\n\n\nworkflow {\n\n    // Read in samplesheet and convert into input sample channel\n    Channel.fromPath(params.input) \\\n        | splitCsv(header:true) \\\n        | map { row-> tuple(row.sample_id, file(row.fastq_1), file(row.fastq_2)) } \\\n        | set {input_reads}\n  \n  input_reads.view()\n\n}\n```\n\nLet's run it with the included samplesheet and example files 👇\n\n```         \nnextflow run main.nf --input docs/example_data/samplesheet.csv --reference ./docs/example_data/GCF_020520425.1_BTI_SOV_V1_chr1-2_genomic_50Mb_trimmed.fna\n```\n\nAssuming everything worked, you should see your `input_reads` channel printed to the console—along with the [colourful nextflow console output](https://seqera.io/blog/nextflow-colored-logs/) (thanks, Phil! 🥳).\n\n### Step 2: Add the First Process\n\nNow, let’s add our first process: quality control (QC) with [fastp](https://github.com/OpenGene/fastp) to preprocess the reads.\n\n```         \n// Check mandatory parameters\nif (params.input) { csv_file = file(params.input) } else { exit 1, 'Input samplesheet not specified!' }\nif (params.reference == null) error \"Please specify a reference genome fasta file with --reference\"\n\ndef reference =  file(params.reference)\n\n/*\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    IMPORT LOCAL MODULES\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n*/\n\ninclude { FASTP } from './modules/local/fastp'\ninclude { SAMTOOLS_FAIDX } from './modules/local/samtools_faidx'\ninclude { BWA_INDEX } from './modules/local/bwa_index'\ninclude { BWA_MEM } from './modules/local/bwa_mem'\ninclude { BCFTOOLS_CALL } from './modules/local/bcftools_call'\n\n\nworkflow {\n\n    // Read in samplesheet and convert into input sample channel\n    Channel.fromPath(params.input) \\\n        | splitCsv(header:true) \\\n        | map { row-> tuple(row.sample_id, file(row.fastq_1), file(row.fastq_2)) } \\\n        | set {input_reads}\n  \n  //input_reads.view()\n  \n  // QC preprocessing of reads\n    FASTP(input_reads)\n    FASTP.out.reads.view()\n\n}\n```\n\nAlright and now lets get into the magic 🪄 of resume. Instead of re-running everything (admittedly it was only a small channel factory process) lets resume from where we left off.\n\n```         \nnextflow run main.nf --input docs/example_data/samplesheet.csv --reference ./docs/example_data/GCF_020520425.1_BTI_SOV_V1_chr1-2_genomic_50Mb_trimmed.fna -resume\n```\n\nSuccess the fastp process has been added to our pipeline 🥳\n\n### Step 3: Map Reads to Reference\n\nNext, let’s map the reads to the reference sequence with [bwa-mem](https://github.com/lh3/bwa), but we’ll need to index the reference first. We’ll add the BWA_INDEX and BWA_MEM processes for this.\n\n```         \n// Check mandatory parameters\nif (params.input) { csv_file = file(params.input) } else { exit 1, 'Input samplesheet not specified!' }\nif (params.reference == null) error \"Please specify a reference genome fasta file with --reference\"\n\ndef reference =  file(params.reference)\n\n/*\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    IMPORT LOCAL MODULES\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n*/\n\ninclude { FASTP } from './modules/local/fastp'\ninclude { SAMTOOLS_FAIDX } from './modules/local/samtools_faidx'\ninclude { BWA_INDEX } from './modules/local/bwa_index'\ninclude { BWA_MEM } from './modules/local/bwa_mem'\ninclude { BCFTOOLS_CALL } from './modules/local/bcftools_call'\n\n\nworkflow {\n\n    // Read in samplesheet and convert into input sample channel\n    Channel.fromPath(params.input) \\\n        | splitCsv(header:true) \\\n        | map { row-> tuple(row.sample_id, file(row.fastq_1), file(row.fastq_2)) } \\\n        | set {input_reads}\n  \n  //input_reads.view()\n  \n  // QC preprocessing of reads\n    FASTP(input_reads)\n    //FASTP.out.reads.view()\n    \n    // Create reference index for BWA\n    BWA_INDEX(reference)\n\n    // Map reads to reference\n    BWA_MEM(FASTP.out.reads, BWA_INDEX.out.index)\n    BWA_MEM.out.bam.view()\n\n\n}\n```\n\nRun the pipeline again with the `-resume` statement 👇\n\n```         \nnextflow run main.nf --input docs/example_data/samplesheet.csv --reference ./docs/example_data/GCF_020520425.1_BTI_SOV_V1_chr1-2_genomic_50Mb_trimmed.fna -resume\n```\n\nIn the console output you should see that it lists the previous FASTP process as cached.\n\n### Step 4: Call Variants\n\nTime for variant calling! We’ll use a [bcftools](https://samtools.github.io/bcftools/) process and index our reference again with [samtools](https://www.htslib.org).\n\nHome stretch now, time to call variants! For this we will use a bcftools process, but we will also need to index our reference again, this time with samtools.\n\n```         \n// Check mandatory parameters\nif (params.input) { csv_file = file(params.input) } else { exit 1, 'Input samplesheet not specified!' }\nif (params.reference == null) error \"Please specify a reference genome fasta file with --reference\"\n\ndef reference =  file(params.reference)\n\n/*\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    IMPORT LOCAL MODULES\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n*/\n\ninclude { FASTP } from './modules/local/fastp'\ninclude { SAMTOOLS_FAIDX } from './modules/local/samtools_faidx'\ninclude { BWA_INDEX } from './modules/local/bwa_index'\ninclude { BWA_MEM } from './modules/local/bwa_mem'\ninclude { BCFTOOLS_CALL } from './modules/local/bcftools_call'\n\n\nworkflow {\n\n    // Read in samplesheet and convert into input sample channel\n    Channel.fromPath(params.input) \\\n        | splitCsv(header:true) \\\n        | map { row-> tuple(row.sample_id, file(row.fastq_1), file(row.fastq_2)) } \\\n        | set {input_reads}\n  \n  //input_reads.view()\n  \n  // QC preprocessing of reads\n    FASTP(input_reads)\n    //FASTP.out.reads.view()\n    \n    // Create reference index for BWA\n    BWA_INDEX(reference)\n\n    // Map reads to reference\n    BWA_MEM(FASTP.out.reads, BWA_INDEX.out.index)\n    //BWA_MEM.out.bam.view()\n\n  // Create reference index for bcftools\n    SAMTOOLS_FAIDX(reference)\n    \n\n    //BWA_MEM.out.bam.map { tuple -> tuple[1] }.collect().view()\n    // Call variants\n    BCFTOOLS_CALL(BWA_MEM.out.bam.map { tuple -> tuple[1] }.collect(), BWA_MEM.out.bai.map { tuple -> tuple[1] }.collect(), reference, SAMTOOLS_FAIDX.out.fai)\n\n\n}\n```\n\nCurious 🤔 about the [map](https://www.nextflow.io/docs/latest/reference/operator.html#map) operator here? It gathers the relevant BAM and BAI components from the output tuples of multiple samples into input channels for BCFTOOLS_CALL. You can uncomment `BWA_MEM.out.bam.view()` and `BWA_MEM.out.bam.map { tuple -> tuple[1] }.collect().view()` to compare the outputs.\n\n::: callout-tip\nIf you ever accidentally run your pipeline without the -resume flag and get that dreaded feeling that you have just lost all the progress on previous processes. No need to worry you can run it again with the -resume flag and and the session ID of the previous run you want to resume from.\n\ne.g. `nextflow run main.nf -resume <session-id>`\n\nDon't know what the session ID is, just run `nextflow log`\n:::\n\nHopefully, this example of modularly building a Nextflow pipeline and using the -resume feature has been helpful! It’s a game-changer for big pipelines or when testing with larger datasets where processes take longer.\n\nAlright Nextflow champions, Happy developing, coding, hacking, or whatever you like to call it!\n\n::: callout-note\nThe example sequencing data found in the related repository and used in this example is from Spinacia oleracea NCBI bioproject \\[PRJNA724923\\](<https://www.ncbi.nlm.nih.gov/bioproject/PRJNA724923>). To keep it small I pre-aligned the samples to chromosome 1 & 2 and then subsetted the mapped reads to form the example fastq files and example genome reference.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}